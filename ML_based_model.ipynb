{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e77c340",
   "metadata": {},
   "source": [
    "## ML Based modelling\n",
    "\n",
    "Training a machine learning model to predict entry and exit points for trading is a complex task that involves multiple steps. Here's a high-level overview of the process:\n",
    "\n",
    "1. **Data Collection and Preprocessing:**\n",
    "   - Collect historical price data, volatility, and RSI data for the asset you want to trade.\n",
    "   - Preprocess the data by cleaning missing values, normalizing/standardizing the features, and splitting it into training and testing sets.\n",
    "\n",
    "2. **Feature Engineering:**\n",
    "   - Create relevant features that the model can use for making predictions. This could include lagged price data, moving averages, technical indicators, and other factors that you believe are important for decision-making.\n",
    "\n",
    "3. **Label Generation:**\n",
    "   - Define the labels for the training dataset. For a binary classification problem (buy/sell), labels could be generated based on price movement after a certain period. For example, if the price increases by a certain threshold after a few periods, label it as a buy signal.\n",
    "\n",
    "4. **Model Selection:**\n",
    "   - Choose a suitable machine learning algorithm for your problem. You could start with algorithms like Random Forest, Gradient Boosting, Support Vector Machines, or Neural Networks.\n",
    "\n",
    "5. **Training the Model:**\n",
    "   - Train the model on the training dataset using the chosen algorithm. Use a combination of features (volatility, RSI, etc.) to predict the labels (buy/sell).\n",
    "\n",
    "6. **Hyperparameter Tuning:**\n",
    "   - Optimize the hyperparameters of your model to improve its performance. This may involve techniques like grid search or random search.\n",
    "\n",
    "7. **Validation and Testing:**\n",
    "   - Evaluate the trained model on the testing dataset to assess its performance. Use metrics like accuracy, precision, recall, and F1-score to measure its effectiveness.\n",
    "\n",
    "8. **Backtesting:**\n",
    "   - Implement the trading strategy using the model's predictions. Simulate the trades in historical data to see how well the model would have performed in the past.\n",
    "\n",
    "9. **Fine-Tuning and Iteration:**\n",
    "   - Analyze the results of backtesting and refine the model if necessary. Adjust parameters, features, or even try different algorithms.\n",
    "\n",
    "10. **Forward Testing and Deployment:**\n",
    "    - Forward test the model on more recent data to ensure its robustness. If satisfied, deploy the model to a live trading environment with proper risk management.\n",
    "\n",
    "11. **Continuous Monitoring and Updating:**\n",
    "    - Continuously monitor the model's performance and update it periodically to adapt to changing market conditions.\n",
    "\n",
    "Please note that developing a successful trading strategy using machine learning is challenging and requires expertise in both trading and data science. Additionally, machine learning models can be prone to overfitting and may not always generalize well to new data. Therefore, it's important to approach this task with caution and consider seeking guidance from experts in both fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2aecd165",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "                   Open         High          Low        Close    Adj Close  \\\n",
      "Date                                                                          \n",
      "2016-01-04  7924.549805  7937.549805  7781.100098  7791.299805  7791.299805   \n",
      "2016-01-05  7828.399902  7831.200195  7763.250000  7784.649902  7784.649902   \n",
      "2016-01-06  7788.049805  7800.950195  7721.200195  7741.000000  7741.000000   \n",
      "2016-01-07  7673.350098  7674.950195  7556.600098  7568.299805  7568.299805   \n",
      "2016-01-08  7611.649902  7634.100098  7581.049805  7601.350098  7601.350098   \n",
      "\n",
      "            Volume   CloseDiff  SMA  RSI  BB_upper  BB_lower  FutureClose  \\\n",
      "Date                                                                        \n",
      "2016-01-04  134700         NaN  NaN  NaN       NaN       NaN  7563.850098   \n",
      "2016-01-05  145200   -6.649902  NaN  NaN       NaN       NaN  7510.299805   \n",
      "2016-01-06  147100  -43.649902  NaN  NaN       NaN       NaN  7562.399902   \n",
      "2016-01-07  188900 -172.700195  NaN  NaN       NaN       NaN  7536.799805   \n",
      "2016-01-08  157400   33.050293  NaN  NaN       NaN       NaN  7437.799805   \n",
      "\n",
      "            PriceChange  Label  \n",
      "Date                            \n",
      "2016-01-04    -0.029193      0  \n",
      "2016-01-05    -0.035242      0  \n",
      "2016-01-06    -0.023072      0  \n",
      "2016-01-07    -0.004162      0  \n",
      "2016-01-08    -0.021516      0  \n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import talib\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 1: Data Collection and Preprocessing\n",
    "\n",
    "def fetch_stock_data(symbol, start_date, end_date):\n",
    "    data = yf.download(symbol, start=start_date, end=end_date)\n",
    "    return data\n",
    "\n",
    "def preprocess_data(data):\n",
    "    data['CloseDiff'] = data['Close'].diff()\n",
    "    data.fillna(method='ffill', inplace=True)\n",
    "    return data\n",
    "\n",
    "# Step 2: Feature Generation\n",
    "\n",
    "def generate_technical_indicators(data):\n",
    "    data['SMA'] = talib.SMA(data['Close'], timeperiod=14)\n",
    "    data['RSI'] = talib.RSI(data['Close'], timeperiod=14)\n",
    "    upper_band, middle_band, lower_band = talib.BBANDS(data['Close'], timeperiod=20)\n",
    "    data['BB_upper'] = upper_band\n",
    "    data['BB_lower'] = lower_band\n",
    "    # Add more technical indicators from talib\n",
    "    return data\n",
    "\n",
    "# Step 3: Label Generation\n",
    "\n",
    "def generate_labels(data, period, threshold):\n",
    "    data['FutureClose'] = data['Close'].shift(-period)\n",
    "    data['PriceChange'] = (data['FutureClose'] - data['Close']) / data['Close']\n",
    "    data['Label'] = np.where(data['PriceChange'] >= threshold, 1, 0)\n",
    "    return data\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    symbol = '^NSEI'  # Replace with your desired stock symbol\n",
    "    start_date = '2016-01-01'\n",
    "    end_date = '2022-01-01'\n",
    "    period = 5  # Number of days into the future\n",
    "    threshold = 0.02  # Price change threshold\n",
    "\n",
    "    # Fetch and preprocess data\n",
    "    stock_data = fetch_stock_data(symbol, start_date, end_date)\n",
    "    preprocessed_data = preprocess_data(stock_data)\n",
    "\n",
    "    # Generate technical indicators\n",
    "    data_with_indicators = generate_technical_indicators(preprocessed_data)\n",
    "\n",
    "    # Generate labels\n",
    "    labeled_data = generate_labels(data_with_indicators, period, threshold)\n",
    "\n",
    "    print(labeled_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2243ce85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "def train_random_forest(X_train, y_train):\n",
    "    rf_model = RandomForestClassifier(random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    return rf_model\n",
    "\n",
    "def train_test_split_data(data, features, label):\n",
    "    X = data[features]\n",
    "    y = data[label]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "def grid_search_model(model, param_grid, X_train, y_train):\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=3)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_true = y_test\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "    \n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    \n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1-Score: {f1:.2f}\")\n",
    "    print(f\"ROC AUC: {roc_auc:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#This code completes steps 4 to 7 of the process. \n",
    "#It trains a Random Forest model, performs a grid search for hyperparameter tuning,\n",
    "#and evaluates the model's accuracy. \n",
    "#You can further customize the hyperparameter grid and \n",
    "#evaluation metrics based on your requirements. \n",
    "#Additionally, you can later explore other machine learning algorithms like \n",
    "#Gradient Boosting, Support Vector Machines, and Neural Networks for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c297d5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.80\n"
     ]
    }
   ],
   "source": [
    "# Select features and label for training\n",
    "features = ['SMA', 'RSI', 'BB_upper', 'BB_lower']  # Add more features here\n",
    "label = 'Label'\n",
    "\n",
    "labeled_data = labeled_data.dropna()\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split_data(labeled_data, features, label)\n",
    "\n",
    "# Train a Random Forest model\n",
    "rf_model = train_random_forest(X_train, y_train)\n",
    "\n",
    "    # Define hyperparameter grid for Random Forest\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Perform grid search for Random Forest\n",
    "best_rf_model = grid_search_model(rf_model, rf_param_grid, X_train, y_train)\n",
    "\n",
    "# Evaluate the best model\n",
    "rf_accuracy = evaluate_model(best_rf_model, X_test, y_test)\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8baaa69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[217  18]\n",
      " [ 39  17]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88       235\n",
      "           1       0.49      0.30      0.37        56\n",
      "\n",
      "    accuracy                           0.80       291\n",
      "   macro avg       0.67      0.61      0.63       291\n",
      "weighted avg       0.78      0.80      0.79       291\n",
      "\n",
      "Accuracy: 0.80\n",
      "Precision: 0.49\n",
      "Recall: 0.30\n",
      "F1-Score: 0.37\n",
      "ROC AUC: 0.61\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_true = y_test\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "    \n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    \n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1-Score: {f1:.2f}\")\n",
    "    print(f\"ROC AUC: {roc_auc:.2f}\")\n",
    "    \n",
    "evaluate_model(best_rf_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4008ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open           264\n",
       "High           264\n",
       "Low            264\n",
       "Close          264\n",
       "Adj Close      264\n",
       "Volume         264\n",
       "CloseDiff      264\n",
       "SMA            264\n",
       "RSI            264\n",
       "BB_upper       264\n",
       "BB_lower       264\n",
       "FutureClose    264\n",
       "PriceChange    264\n",
       "Label          264\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_data[labeled_data.Label==1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e723c533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open           1188\n",
       "High           1188\n",
       "Low            1188\n",
       "Close          1188\n",
       "Adj Close      1188\n",
       "Volume         1188\n",
       "CloseDiff      1188\n",
       "SMA            1188\n",
       "RSI            1188\n",
       "BB_upper       1188\n",
       "BB_lower       1188\n",
       "FutureClose    1188\n",
       "PriceChange    1188\n",
       "Label          1188\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_data[labeled_data.Label==0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fd26c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef0ce92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82952a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
